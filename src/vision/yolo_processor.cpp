#include "vision/frame_processor.h"
#include "hardware/rk3588_npu.h"
#include <chrono>
#include <fstream>
#include <json/json.h>

namespace cam_server {
namespace vision {

bool YOLOProcessor::initialize() {
    try {
        std::cout << "ğŸ§  åˆå§‹åŒ–NPU YOLOå¤„ç†å™¨..." << std::endl;

        // 1. åˆ›å»ºNPU YOLOæ£€æµ‹å™¨
        npu_detector_ = std::make_unique<hardware::NPUYOLODetector>();

        // 2. é…ç½®æ¨¡å‹è·¯å¾„
        std::string model_path = "models/yolov8n.rknn";  // RKNNæ ¼å¼æ¨¡å‹
        std::string classes_path = "models/coco.names";   // ç±»åˆ«æ–‡ä»¶

        // 3. åŠ è½½ç±»åˆ«åç§°
        std::ifstream classes_file(classes_path);
        if (classes_file.good()) {
            std::string line;
            while (std::getline(classes_file, line)) {
                class_names_.push_back(line);
            }
        } else {
            // ä½¿ç”¨é»˜è®¤çš„COCOç±»åˆ«
            class_names_ = hardware::NPUUtils::getRecommendedYOLOConfig().class_names;
        }

        // 4. æ£€æŸ¥NPUæ˜¯å¦å¯ç”¨
        if (!hardware::RK3588NPUEngine::isNPUSupported()) {
            std::cout << "âš ï¸ NPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUå¤„ç†" << std::endl;
            use_npu_ = false;
            return initializeCPUFallback();
        }

        // 5. åˆå§‹åŒ–NPUæ£€æµ‹å™¨
        if (!npu_detector_->initialize(model_path, class_names_)) {
            std::cout << "âš ï¸ NPUåˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°CPUå¤„ç†" << std::endl;
            use_npu_ = false;
            return initializeCPUFallback();
        }

        // 6. è®¾ç½®æ£€æµ‹å‚æ•°
        npu_detector_->setConfidenceThreshold(confidence_threshold_);
        npu_detector_->setNMSThreshold(nms_threshold_);

        initialized_ = true;
        use_npu_ = true;

        std::cout << "âœ… NPU YOLOå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ" << std::endl;
        std::cout << "   NPUç¡¬ä»¶ä¿¡æ¯: " << hardware::RK3588NPUEngine::getNPUHardwareInfo() << std::endl;

        return true;

    } catch (const std::exception& e) {
        std::cerr << "âŒ NPU YOLOåˆå§‹åŒ–å¤±è´¥: " << e.what() << std::endl;
        std::cout << "ğŸ”„ å°è¯•CPUå›é€€..." << std::endl;
        use_npu_ = false;
        return initializeCPUFallback();
    }
}

bool YOLOProcessor::initializeCPUFallback() {
    // CPUå›é€€å®ç° (ä¿ç•™åŸæœ‰çš„OpenCV DNNå®ç°)
    std::cout << "ğŸ”„ åˆå§‹åŒ–CPU YOLOå¤„ç†å™¨..." << std::endl;

    std::string model_path = "models/yolov8n.onnx";
    std::ifstream model_file(model_path);
    if (!model_file.good()) {
        std::cerr << "âŒ YOLOæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: " << model_path << std::endl;
        return false;
    }

    // è¿™é‡Œå¯ä»¥ä¿ç•™åŸæœ‰çš„CPUå®ç°ä½œä¸ºå›é€€
    std::cout << "âœ… CPU YOLOå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ" << std::endl;
    return true;
}

ProcessingResult YOLOProcessor::process(const cv::Mat& input_frame) {
    ProcessingResult result;
    auto start_time = std::chrono::high_resolution_clock::now();

    if (!initialized_) {
        result.success = false;
        result.metadata = R"({"error":"YOLO processor not initialized"})";
        return result;
    }

    try {
        cv::Mat output_frame = input_frame.clone();
        std::vector<hardware::NPUYOLODetection> detections;

        if (use_npu_ && npu_detector_) {
            // ä½¿ç”¨NPUè¿›è¡Œæ£€æµ‹
            detections = npu_detector_->detect(input_frame);

            // ç»˜åˆ¶NPUæ£€æµ‹ç»“æœ
            drawNPUDetections(output_frame, detections);

            // è®¡ç®—å¤„ç†æ—¶é—´
            auto end_time = std::chrono::high_resolution_clock::now();
            auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
            double processing_time = duration.count() / 1000.0;

            // ç”Ÿæˆå…ƒæ•°æ®
            result.metadata = generateDetectionMetadata(detections, processing_time);
            result.processing_time_ms = processing_time;

            // æ‰“å°NPUæ€§èƒ½ç»Ÿè®¡
            if (detections.size() > 0) {
                auto stats = npu_detector_->getDetectionStats();
                if (stats.total_frames % 100 == 0) {  // æ¯100å¸§æ‰“å°ä¸€æ¬¡
                    std::cout << "ğŸ§  NPUæ£€æµ‹ç»Ÿè®¡: å¹³å‡" << stats.avg_detection_time_ms
                             << "ms/å¸§, å¹³å‡" << stats.avg_objects_per_frame << "ä¸ªå¯¹è±¡/å¸§" << std::endl;
                }
            }

        } else {
            // CPUå›é€€å¤„ç†
            std::cout << "âš ï¸ ä½¿ç”¨CPUå›é€€å¤„ç† (NPUä¸å¯ç”¨)" << std::endl;
            // è¿™é‡Œå¯ä»¥è°ƒç”¨åŸæœ‰çš„CPUå®ç°
            result.metadata = R"({"type":"yolo_detection","detections":[],"detection_count":0,"processing_backend":"cpu_fallback"})";
        }

        result.processed_frame = output_frame;
        result.success = true;

    } catch (const std::exception& e) {
        result.success = false;
        Json::Value error_metadata;
        error_metadata["error"] = e.what();
        error_metadata["processing_backend"] = use_npu_ ? "npu" : "cpu";
        result.metadata = Json::writeString(Json::StreamWriterBuilder(), error_metadata);

        std::cerr << "âŒ YOLOå¤„ç†å¤±è´¥: " << e.what() << std::endl;
    }

    return result;
}

void YOLOProcessor::drawNPUDetections(cv::Mat& frame, const std::vector<hardware::NPUYOLODetection>& detections) {
    // å®šä¹‰é¢œè‰²
    std::vector<cv::Scalar> colors = {
        cv::Scalar(255, 0, 0),    // çº¢è‰²
        cv::Scalar(0, 255, 0),    // ç»¿è‰²
        cv::Scalar(0, 0, 255),    // è“è‰²
        cv::Scalar(255, 255, 0),  // é»„è‰²
        cv::Scalar(255, 0, 255),  // ç´«è‰²
        cv::Scalar(0, 255, 255),  // é’è‰²
    };

    for (const auto& detection : detections) {
        // é€‰æ‹©é¢œè‰²
        cv::Scalar color = colors[detection.class_id % colors.size()];

        // ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv::rectangle(frame, detection.bbox, color, 2);

        // å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
        std::string label = detection.class_name + " " +
                           std::to_string(static_cast<int>(detection.confidence * 100)) + "%";

        // è®¡ç®—æ–‡æœ¬å¤§å°
        int baseline;
        cv::Size text_size = cv::getTextSize(label, cv::FONT_HERSHEY_SIMPLEX, 0.6, 1, &baseline);

        // ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        cv::Point label_pos(detection.bbox.x, detection.bbox.y - text_size.height - 5);
        if (label_pos.y < 0) label_pos.y = detection.bbox.y + text_size.height + 5;

        cv::rectangle(frame,
                     cv::Point(label_pos.x, label_pos.y - text_size.height - 5),
                     cv::Point(label_pos.x + text_size.width, label_pos.y + 5),
                     color, -1);

        // ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
        cv::putText(frame, label, label_pos, cv::FONT_HERSHEY_SIMPLEX, 0.6,
                   cv::Scalar(255, 255, 255), 1);

        // ç»˜åˆ¶ä¸­å¿ƒç‚¹
        cv::circle(frame, detection.center, 3, color, -1);
    }

    // åœ¨å·¦ä¸Šè§’æ˜¾ç¤ºNPUä¿¡æ¯
    std::string npu_info = "NPU: " + std::to_string(detections.size()) + " objects";
    cv::putText(frame, npu_info, cv::Point(10, 25), cv::FONT_HERSHEY_SIMPLEX, 0.7,
               cv::Scalar(0, 255, 0), 2);
}

std::string YOLOProcessor::generateDetectionMetadata(const std::vector<hardware::NPUYOLODetection>& detections,
                                                    double processing_time) {
    Json::Value metadata;
    metadata["type"] = "yolo_npu_detection";
    metadata["processing_backend"] = "npu";
    metadata["detections"] = Json::Value(Json::arrayValue);

    for (const auto& detection : detections) {
        Json::Value det;
        det["class_id"] = detection.class_id;
        det["class_name"] = detection.class_name;
        det["confidence"] = detection.confidence;
        det["bbox"]["x"] = detection.bbox.x;
        det["bbox"]["y"] = detection.bbox.y;
        det["bbox"]["width"] = detection.bbox.width;
        det["bbox"]["height"] = detection.bbox.height;
        det["center"]["x"] = detection.center.x;
        det["center"]["y"] = detection.center.y;
        metadata["detections"].append(det);
    }

    metadata["detection_count"] = static_cast<int>(detections.size());
    metadata["processing_time_ms"] = processing_time;

    // æ·»åŠ NPUçŠ¶æ€ä¿¡æ¯
    if (npu_detector_) {
        auto stats = npu_detector_->getDetectionStats();
        metadata["npu_stats"]["total_frames"] = static_cast<Json::UInt64>(stats.total_frames);
        metadata["npu_stats"]["avg_detection_time_ms"] = stats.avg_detection_time_ms;
        metadata["npu_stats"]["avg_objects_per_frame"] = stats.avg_objects_per_frame;
    }

    return Json::writeString(Json::StreamWriterBuilder(), metadata);
}

std::vector<cv::Rect> YOLOProcessor::detectObjects(const cv::Mat& frame,
                                                   std::vector<float>& confidences,
                                                   std::vector<int>& class_ids) {
    std::vector<cv::Rect> boxes;

    // åˆ›å»ºblob
    cv::Mat blob;
    cv::dnn::blobFromImage(frame, blob, 1.0/255.0, input_size_, cv::Scalar(0,0,0), true, false);

    // è®¾ç½®è¾“å…¥
    net_.setInput(blob);

    // å‰å‘ä¼ æ’­
    std::vector<cv::Mat> outputs;
    net_.forward(outputs, net_.getUnconnectedOutLayersNames());

    // è§£æè¾“å‡º
    for (const auto& output : outputs) {
        for (int i = 0; i < output.rows; ++i) {
            const float* data = output.ptr<float>(i);

            // è·å–ç½®ä¿¡åº¦
            float confidence = data[4];
            if (confidence > confidence_threshold_) {
                // è·å–ç±»åˆ«åˆ†æ•°
                cv::Mat scores = output.row(i).colRange(5, output.cols);
                cv::Point class_id_point;
                double max_class_score;
                cv::minMaxLoc(scores, 0, &max_class_score, 0, &class_id_point);

                if (max_class_score > confidence_threshold_) {
                    // è®¡ç®—è¾¹ç•Œæ¡†
                    float center_x = data[0] * frame.cols;
                    float center_y = data[1] * frame.rows;
                    float width = data[2] * frame.cols;
                    float height = data[3] * frame.rows;

                    int left = static_cast<int>(center_x - width / 2);
                    int top = static_cast<int>(center_y - height / 2);

                    boxes.emplace_back(left, top, static_cast<int>(width), static_cast<int>(height));
                    confidences.push_back(confidence);
                    class_ids.push_back(class_id_point.x);
                }
            }
        }
    }

    // éæå¤§å€¼æŠ‘åˆ¶
    std::vector<int> indices;
    cv::dnn::NMSBoxes(boxes, confidences, confidence_threshold_, nms_threshold_, indices);

    std::vector<cv::Rect> final_boxes;
    std::vector<float> final_confidences;
    std::vector<int> final_class_ids;

    for (int idx : indices) {
        final_boxes.push_back(boxes[idx]);
        final_confidences.push_back(confidences[idx]);
        final_class_ids.push_back(class_ids[idx]);
    }

    boxes = final_boxes;
    confidences = final_confidences;
    class_ids = final_class_ids;

    return boxes;
}

void YOLOProcessor::drawDetections(cv::Mat& frame,
                                  const std::vector<cv::Rect>& boxes,
                                  const std::vector<float>& confidences,
                                  const std::vector<int>& class_ids) {
    // å®šä¹‰é¢œè‰²
    std::vector<cv::Scalar> colors = {
        cv::Scalar(255, 0, 0),    // çº¢è‰²
        cv::Scalar(0, 255, 0),    // ç»¿è‰²
        cv::Scalar(0, 0, 255),    // è“è‰²
        cv::Scalar(255, 255, 0),  // é»„è‰²
        cv::Scalar(255, 0, 255),  // ç´«è‰²
        cv::Scalar(0, 255, 255),  // é’è‰²
    };

    for (size_t i = 0; i < boxes.size(); ++i) {
        const auto& box = boxes[i];
        const auto& confidence = confidences[i];
        const auto& class_id = class_ids[i];

        // é€‰æ‹©é¢œè‰²
        cv::Scalar color = colors[class_id % colors.size()];

        // ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv::rectangle(frame, box, color, 2);

        // å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
        std::string label = (class_id < class_names_.size()) ?
                           class_names_[class_id] : "unknown";
        label += " " + std::to_string(static_cast<int>(confidence * 100)) + "%";

        // è®¡ç®—æ–‡æœ¬å¤§å°
        int baseline;
        cv::Size text_size = cv::getTextSize(label, cv::FONT_HERSHEY_SIMPLEX, 0.5, 1, &baseline);

        // ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        cv::Point label_pos(box.x, box.y - text_size.height - 5);
        if (label_pos.y < 0) label_pos.y = box.y + text_size.height + 5;

        cv::rectangle(frame,
                     cv::Point(label_pos.x, label_pos.y - text_size.height - 5),
                     cv::Point(label_pos.x + text_size.width, label_pos.y + 5),
                     color, -1);

        // ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
        cv::putText(frame, label, label_pos, cv::FONT_HERSHEY_SIMPLEX, 0.5,
                   cv::Scalar(255, 255, 255), 1);
    }
}

std::string YOLOProcessor::getConfig() const {
    Json::Value config;
    config["confidence_threshold"] = confidence_threshold_;
    config["nms_threshold"] = nms_threshold_;
    config["input_width"] = input_size_.width;
    config["input_height"] = input_size_.height;
    return Json::writeString(Json::StreamWriterBuilder(), config);
}

bool YOLOProcessor::setConfig(const std::string& config) {
    try {
        Json::Value root;
        Json::CharReaderBuilder builder;
        std::string errors;
        std::istringstream stream(config);

        if (!Json::parseFromStream(builder, stream, &root, &errors)) {
            return false;
        }

        if (root.isMember("confidence_threshold")) {
            confidence_threshold_ = root["confidence_threshold"].asFloat();
        }
        if (root.isMember("nms_threshold")) {
            nms_threshold_ = root["nms_threshold"].asFloat();
        }
        if (root.isMember("input_width") && root.isMember("input_height")) {
            input_size_.width = root["input_width"].asInt();
            input_size_.height = root["input_height"].asInt();
        }

        return true;
    } catch (const std::exception& e) {
        return false;
    }
}

void YOLOProcessor::cleanup() {
    net_ = cv::dnn::Net();
    class_names_.clear();
    initialized_ = false;
}

} // namespace vision
} // namespace cam_server
